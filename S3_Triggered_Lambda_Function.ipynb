{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1328301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.parse\n",
    "import boto3\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    print(event)\n",
    "    s3 = boto3.client('s3')\n",
    "    comprehend = boto3.client(\"comprehend\")\n",
    "    s3_writer = boto3.resource('s3')\n",
    "    \n",
    "    #print(\"Received event: \" + json.dumps(event, indent=2))\n",
    "    \n",
    "    # Get the object from the event and show its content type\n",
    "    bucket = event['Records'][0]['s3']['bucket']['name']\n",
    "    key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'], encoding='utf-8')\n",
    "    print(key)\n",
    "    \n",
    "    # Fetching latest file added to the bucket.\n",
    "    objs = s3.list_objects_v2(Bucket=bucket, Prefix='Data/stream/')['Contents']\n",
    "    sorted_objs = sorted(objs,key = lambda obj: obj['LastModified'],reverse=True)\n",
    "    resent_file = s3.get_object(\n",
    "                    Bucket=bucket,\n",
    "                    Key=sorted_objs[0]['Key'])\n",
    "     \n",
    "    print(resent_file)\n",
    "    \n",
    "    # Reading file contents.\n",
    "    content = resent_file['Body'].read().decode().rstrip('\\n')\n",
    "    content = content.split('\\n')\n",
    "    \n",
    "    # Performing Tweets Sentiments and storing each tweet inside a list.\n",
    "    transformed_tweets = []\n",
    "    for tweet in content:\n",
    "        \n",
    "        tweet = json.loads(tweet)\n",
    "        # Removing non ascii characters (emojis) from text \n",
    "        tweet_txt = tweet['text'].encode('ASCII','ignore').decode()\n",
    "        # Getting text sentiment analysis\n",
    "        sentiment = comprehend.detect_sentiment(Text=tweet_txt, LanguageCode=\"en\")\n",
    "        # Collecting tweet sentiment info into dictionary\n",
    "        sentiment_tweet = {}\n",
    "        sentiment_tweet['tweet_id'] = tweet['tweet_id']\n",
    "        sentiment_tweet['Sentiment'] = sentiment['Sentiment']\n",
    "        sentiment_tweet['Processed_text'] = tweet_txt\n",
    "        \n",
    "        transformed_tweets.append(sentiment_tweet)\n",
    "    \n",
    "    # Saving json data as string and adding new line character after each tweet.\n",
    "    transformed_tweets = json.dumps(transformed_tweets)[1:-1].replace('},','}\\n')\n",
    "    # Renaming the sentiment file similar to the event file but with few name changes.\n",
    "    output_file = key.replace('stream/','sentiment/').replace('Ingest','sentiment')\n",
    "    # Writing sentiment file to S3 bucket.\n",
    "    file_writer= s3_writer.Object(bucket, output_file)\n",
    "    respond = file_writer.put(Body=transformed_tweets.encode())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
